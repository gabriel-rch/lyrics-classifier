name: ETL Pipeline
on:
  workflow_dispatch:

jobs:
  # First extraction job
  extract-letras:
    name: extract lyrics from Letras.mus.br
    runs-on: ubuntu-latest
    steps:
      - name: checkout repository
        uses: actions/checkout@v4.2.2
      - name: setup the python environment
        uses: ./.github/actions/python-setup
      - name: run the extraction script
        run: python etl/extract.py --source letras
      - name: cache data
        uses: actions/cache@v4.2.0
        with:
          path: ./letras.json
          key: from-letras-${{ github.run_id }}
  # Second extraction job, paralel to the first one
  extract-vagalume:
    name: extract lyrics from Vagalume.com.br
    runs-on: ubuntu-latest
    steps:
      - name: checkout repository
        uses: actions/checkout@v4.2.2
      - name: setup the python environment
        uses: ./.github/actions/python-setup
      - name: run the extraction script
        run: python etl/extract.py --source vagalume
      - name: cache data
        uses: actions/cache@v4.2.0
        with:
          path: ./vagalume.json
          key: from-vagalume-${{ github.run_id }}
  # Transformation job, requires both extraction jobs to be completed
  transform:
    name: transform data into tabular format
    runs-on: ubuntu-latest
    needs: [extract-letras, extract-vagalume]
    steps:
      - name: checkout repository
        uses: actions/checkout@v4.2.2
      - name: setup the python environment
        uses: ./.github/actions/python-setup
      - name: restore extracted data from Letras
        uses: actions/cache@v4.2.0
        with:
          path: output_a.txt
          key: from-letras-${{ github.run_id }}
          restore-keys: |
            from-letras-
      - name: restore extracted data from Vagalume
        uses: actions/cache@v4.2.0
        with:
          path: ./vagalume.json
          key: from-vagalume-${{ github.run_id }}
          restore-keys: |
            from-vagalume-
      - name: run the transformation script
        run: python etl/transform.py
      - name: cache structured data
        uses: actions/cache@v4.2.0
        with:
          path: ./lyrics.csv
          key: structured-lyrics-${{ github.run_id }}
  # Loading job, executed after the transformation step
  load:
    name: load data to HopsWorks
    runs-on: ubuntu-latest
    needs: transform
    steps:
      - name: checkout repository
        uses: actions/checkout@v4.2.2
      - name: setup the python environment
        uses: ./.github/actions/python-setup
      - name: recover structured data
        uses: actions/cache@v4.2.0
        with:
          path: ./lyrics.csv
          key: structured-lyrics-${{ github.run_id }}
          restore-keys: |
            structured-lyrics-
      - name: upload the data
        env:
          HOPSWORKS_KEY: ${{ secrets.HOPSWORKS_KEY }}
        run: python etl/load.py
